{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Day 4: Passport Processing ---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With the toboggan login problems resolved, you set off toward the airport. While travel by toboggan might be easy, it's certainly not safe: there's very minimal steering and the area is covered in trees. You'll need to see which angles will take you near the fewest trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byr (Birth Year)\n",
    "cid (Country ID)\n",
    "ecl (Eye Color)\n",
    "eyr (Expiration Year)\n",
    "hcl (Hair Color)\n",
    "hgt (Height)\n",
    "iyr (Issue Year)\n",
    "pid (Passport ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=179>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_validity(arr, part2):     \n",
    "    arr_decoded = tf.strings.unicode_decode(arr[:,0], 'UTF-8').to_tensor()-97\n",
    "    i = tf.argsort((26*arr_decoded[:,0]) + arr_decoded[:,1])\n",
    "    arr = tf.gather(arr, i)\n",
    "    \n",
    "    if tf.shape(arr)[0] < 7:\n",
    "        return False\n",
    "\n",
    "    if tf.shape(arr)[0] == 7 and arr[1][0] == 'cid' or arr[0][0] == 'cid':\n",
    "        return False\n",
    "    \n",
    "    offset = 0\n",
    "    \n",
    "    if tf.shape(arr)[0] == 8:\n",
    "        offset = 1\n",
    "    \n",
    "    if not part2:\n",
    "        return True\n",
    "    \n",
    "    # Just because it needs to be initialized everywhere\n",
    "    x = 0.0\n",
    "    \n",
    "    x = tf.strings.to_number(arr[0][1])\n",
    "    byr_t = x >= 1920 and x <= 2002\n",
    "\n",
    "    ecl_t = tf.strings.regex_full_match(arr[1+offset][1], '^(amb|blu|brn|gry|grn|hzl|oth)$')\n",
    "\n",
    "    x = tf.strings.to_number(arr[2+offset][1])\n",
    "    eyr_t = x >= 2020 and x <= 2030\n",
    "\n",
    "    hcl_t = tf.strings.regex_full_match(arr[3+offset][1], '^#[0-9a-f][0-9a-f][0-9a-f][0-9a-f][0-9a-f][0-9a-f]$')\n",
    "\n",
    "    hgt_t = False\n",
    "    hgt_s_size = tf.strings.length(arr[4+offset][1])\n",
    "    x = tf.strings.to_number(tf.strings.substr(arr[4+offset][1], 0, hgt_s_size-2))\n",
    "\n",
    "    if tf.strings.substr(arr[4+offset][1], -2, 2) == \"cm\":\n",
    "        hgt_t = x >= 150 and x <= 193\n",
    "    elif tf.strings.substr(arr[4+offset][1], -2, 2) == \"in\":\n",
    "        hgt_t = x >= 59 and x <= 76\n",
    "\n",
    "    x = tf.strings.to_number(arr[5+offset][1])\n",
    "    iyr_t = x >= 2002 and x <= 2020\n",
    "        \n",
    "    pid_t = tf.strings.length(arr[6+offset][1]) == 9\n",
    "        \n",
    "    return byr_t and ecl_t and eyr_t and hcl_t and hgt_t and iyr_t and pid_t\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def solve(fname, part2=False):\n",
    "    s = tf.io.read_file(fname)\n",
    "    s = tf.strings.split(s, \"\\n\\n\")\n",
    "    s = tf.map_fn(lambda s: tf.strings.regex_replace(s, '\\n', ' '), s)\n",
    "    s = tf.strings.split(s, ' ')\n",
    "    s = tf.strings.split(s, ':')\n",
    "\n",
    "    \n",
    "    bools = tf.map_fn(lambda x: check_validity(x.to_tensor(), part2), s, fn_output_signature=tf.TensorSpec(shape=(), dtype=tf.bool, name=None))\n",
    "    \n",
    "    return tf.math.count_nonzero(bools)\n",
    "        \n",
    "solve('day4.txt', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837 ms ± 12.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "solve('day4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13 s ± 4.02 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "solve('day4.txt', part2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Set up logging.\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = 'logs/func/%s' % stamp\n",
    "\n",
    "# Bracket the function call with\n",
    "# tf.summary.trace_on() and tf.summary.trace_export().\n",
    "tf.profiler.experimental.start(logdir)\n",
    "solve('day4.txt')\n",
    "tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
